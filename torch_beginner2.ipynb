{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdj0yY+ucQXvw/rA+hShMq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RichaTiwari14/Pytorch_trial/blob/main/torch_beginner2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7lhx7K_CmgF",
        "outputId": "f0bdbf40-1a7c-4c99-c3b2-7ccd4f5676b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "GPA available\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch as nn\n",
        "print(torch.__version__)\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPA available\")\n",
        "  print(torch.cuda.get_device_name())\n",
        "else:\n",
        "  print(\"GPU not available\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#empty() doesn't assign any value only allocates memory to the dimension and returns values already existing in that memory\n",
        "print(\"Empty():\",torch.empty(2,3))\n",
        "\n",
        "#type()\n",
        "a=torch.rand(2,3)\n",
        "type(a) #returns type of the variable\n",
        "\n",
        "#ones() assigns value 1 to the memory\n",
        "torch.ones(2,2)\n",
        "\n",
        "#zeros() assigns value 0 to the memory\n",
        "torch.zeros(2,2)\n",
        "\n",
        "#rand() assigns random values to the memory\n",
        "torch.rand(2,2)\n",
        "\n",
        "#manual_seed()   used to generate same random values....just use this rand() with the same manual_seed()\n",
        "torch.manual_seed(100)\n",
        "print(torch.rand(2,3))\n",
        "\n",
        "#tensor() to direct assign the given values\n",
        "torch.tensor([[2,3,4],[1.2,3.2,0.2]])\n",
        "\n",
        "#arange() works same as range, give the initial and final(x-1) and step (i,f,s)value and it will return the values falling in between\n",
        "torch.arange(0,10,2)\n",
        "\n",
        "#linspace()\n",
        "torch.linspace(0,10,10)\n",
        "\n",
        "#eye() sets the dimension\n",
        "torch.eye(10)\n",
        "\n",
        "#full() first set dimension in bracket then value to assign in that memory\n",
        "torch.full((3,3),5)\n",
        "\n",
        "#shape()\n",
        "(torch.tensor([[1,2,3],[1.2,3.2,6.2]])).shape\n",
        "\n",
        "#OR\n",
        "\n",
        "x=torch.tensor([[1,2,3],[1.2,3.2,6.2]])\n",
        "x.shape\n",
        "\n",
        "#empty_like() will generate empty() method value in the same dimension as x\n",
        "torch.empty_like(x)\n",
        "\n",
        "#zeros_like()\n",
        "torch.zeros_like(x)\n",
        "\n",
        "#ones_like()\n",
        "torch.ones_like(x)\n",
        "\n",
        "#rand_like()  won't work as the rest of methods generate int value whereas rand genrates floats between 0-1\n",
        "\n",
        "#dtype() to know the data type\n",
        "x.dtype\n",
        "\n",
        "a=torch.tensor([1.2,2.3,3.4],dtype=torch.int32) #converting the given tensor into int\n",
        "torch.tensor([2,3,4],dtype=torch.float64) # converting the given tensor into float\n",
        "\n",
        "x.to(torch.int32) #converting the already existing tensor into another   eg.float to int\n",
        "torch.rand_like(a,dtype=torch.float32) #\n",
        "\n",
        "#ceil()\n",
        "torch.ceil(a) #it gives nearest greater integer\n",
        "\n",
        "#floor()\n",
        "torch.floor(a) #it gives nearest smaller integer\n",
        "\n",
        "print(a+2) #adddition\n",
        "print(a-2) #subtraction\n",
        "print(a*2)  #multiplication\n",
        "print(a/2) #division ( returns float value)\n",
        "print(a//2) #floor division (returns integer value)\n",
        "print(a**2) #power\n",
        "print(torch.abs(a))  #returns absolute value\n",
        "print(torch.neg(a)) #returns negative value\n",
        "print(torch.round(a)) #returns round figure\n",
        "print(torch.clamp(a, min=2,max=5))  #returns value with min and max limit set\n",
        "z=torch.randint(size=(2,3),low=3,high=10) #returns random integer values having limit set low, high\n",
        "print(z)\n",
        "print(torch.sum(z,dim=0)) #make sum of values of columns compressing it to the given dimension\n",
        "print(torch.sum(z,dim=1))\n",
        "\n",
        "#mean() to use this method the tensor should be float, therefore convert it to float\n",
        "e=z.to(torch.float32)\n",
        "print(e)\n",
        "print(torch.mean(e)) #mean of whole\n",
        "print(torch.mean(e,dim=1)) #on the basis of row\n",
        "print(torch.mean(e,dim=0)) #on the basis of col\n",
        "\n",
        "#median()\n",
        "print(torch.median(e)) #median of whole\n",
        "print(torch.median(e,dim=0)) #on the basis of col\n",
        "print(torch.median(e,dim=1)) #on the basis of row\n",
        "\n",
        "#max() & min()\n",
        "print(torch.max(e))\n",
        "print(torch.min(e))\n",
        "\n",
        "#prod() to find out product\n",
        "print(torch.prod(e))\n",
        "\n",
        "#std() to find out standard deviation\n",
        "print(torch.std(e))\n",
        "\n",
        "#var() to find out variance\n",
        "print(torch.var(e))\n",
        "\n",
        "#argmax() to find out the position of the max value\n",
        "print(torch.argmax(e))\n",
        "\n",
        "#argmin() to find out position of the min value\n",
        "print(torch.argmin(e))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miTUV78SUGBn",
        "outputId": "f06c53c2-510c-4e1e-e6d2-208b8593fd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty(): tensor([[1.8123e+35, 4.5139e-41, 1.2572e-33],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
            "tensor([[0.1117, 0.8158, 0.2626],\n",
            "        [0.4839, 0.6765, 0.7539]])\n",
            "tensor([3, 4, 5], dtype=torch.int32)\n",
            "tensor([-1,  0,  1], dtype=torch.int32)\n",
            "tensor([2, 4, 6], dtype=torch.int32)\n",
            "tensor([0.5000, 1.0000, 1.5000])\n",
            "tensor([0, 1, 1], dtype=torch.int32)\n",
            "tensor([1, 4, 9], dtype=torch.int32)\n",
            "tensor([1, 2, 3], dtype=torch.int32)\n",
            "tensor([-1, -2, -3], dtype=torch.int32)\n",
            "tensor([1, 2, 3], dtype=torch.int32)\n",
            "tensor([2, 2, 3], dtype=torch.int32)\n",
            "tensor([[6, 7, 8],\n",
            "        [8, 7, 5]])\n",
            "tensor([14, 14, 13])\n",
            "tensor([21, 20])\n",
            "tensor([[6., 7., 8.],\n",
            "        [8., 7., 5.]])\n",
            "tensor(6.8333)\n",
            "tensor([7.0000, 6.6667])\n",
            "tensor([7.0000, 7.0000, 6.5000])\n",
            "tensor(7.)\n",
            "torch.return_types.median(\n",
            "values=tensor([6., 7., 5.]),\n",
            "indices=tensor([0, 0, 1]))\n",
            "torch.return_types.median(\n",
            "values=tensor([7., 7.]),\n",
            "indices=tensor([1, 1]))\n",
            "tensor(8.)\n",
            "tensor(5.)\n",
            "tensor(94080.)\n",
            "tensor(1.1690)\n",
            "tensor(1.3667)\n",
            "tensor(2)\n",
            "tensor(5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#matrix multiplication\n",
        "a=torch.tensor([[2.2,3.4,5.1],[4.2,5.2,3.2]])\n",
        "b=torch.tensor([[3.3,4.2],[0.1,0.3],[2.2,3.3]])\n",
        "torch.matmul(a,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOG6Fct-hayf",
        "outputId": "4ab3c3c3-bbd0-4c0b-ee08-942ad1376117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[18.8200, 27.0900],\n",
              "        [21.4200, 29.7600]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dot products\n",
        "vector1=torch.tensor([2,3])\n",
        "vector2=torch.tensor([4,5])\n",
        "print(torch.dot(vector1,vector2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuLtCxdHkGTv",
        "outputId": "cac46303-1f1f-4023-d175-40288406d2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e #printing e without using print\n",
        "torch.transpose(e,0,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDplZc_ZlqA1",
        "outputId": "29aa316c-dad3-4a4a-afe6-799039ed0c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6., 8.],\n",
            "        [7., 7.],\n",
            "        [8., 5.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.tensor([[1,2],[3,2]])\n",
        "b=a.to(torch.float32)\n",
        "torch.det(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdY3H3KhoRMf",
        "outputId": "6d5ad820-3d5a-4baa-f782-c752ef3f2a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-4.)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inverse()\n",
        "torch.inverse(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ3BLIjGubIM",
        "outputId": "f86ebd1f-cf1e-4677-d803-d187d0186afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5000,  0.5000],\n",
              "        [ 0.7500, -0.2500]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.tensor([[2,2],[4,5]])\n",
        "b=torch.tensor([[6,2],[8,1]])\n",
        "#to compare each values\n",
        "#comparision operator\n",
        "print(a>b)\n",
        "print(a<b)\n",
        "print(a==b)\n",
        "print(a!=b)\n",
        "print(a<=b)\n",
        "print(a>=b)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TV1DHvbxZjS",
        "outputId": "36470495-a55d-4dd4-da59-9180c1d0101e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False, False],\n",
            "        [False,  True]])\n",
            "tensor([[ True, False],\n",
            "        [ True, False]])\n",
            "tensor([[False,  True],\n",
            "        [False, False]])\n",
            "tensor([[ True, False],\n",
            "        [ True,  True]])\n",
            "tensor([[ True,  True],\n",
            "        [ True, False]])\n",
            "tensor([[False,  True],\n",
            "        [False,  True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#log() to find logrithm\n",
        "a=torch.randint(size=(2,3),low=3,high=10)\n",
        "b=a.to(torch.float32)\n",
        "torch.log(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYeANyS93hfG",
        "outputId": "0b2ad6c6-533b-4601-92fb-1f95271b50d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0986, 1.3863, 2.0794],\n",
              "        [2.1972, 2.1972, 1.3863]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exponent exp()\n",
        "torch.exp(a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrVpuGi_4Fjd",
        "outputId": "d5e4b5b9-8824-4e8f-9338-4b02fbd1ea60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  20.0855, 2980.9580,   54.5981],\n",
              "        [  54.5981,  148.4132, 2980.9580]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sqrt()\n",
        "print(torch.sqrt(a))\n",
        "\n",
        "#sigmoid()\n",
        "print(torch.sigmoid(a))\n",
        "\n",
        "#softmax()  not applicable for long\n",
        "print(torch.softmax(b,dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCoi21rT4VVa",
        "outputId": "413306f0-6804-40bd-a858-94886032cb52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.7321, 2.0000, 2.8284],\n",
            "        [3.0000, 3.0000, 2.0000]])\n",
            "tensor([[0.9526, 0.9820, 0.9997],\n",
            "        [0.9999, 0.9999, 0.9820]])\n",
            "tensor([[0.0025, 0.0067, 0.9820],\n",
            "        [0.9975, 0.9933, 0.0180]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#relu() rectified linear unit\n",
        "torch.relu(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WPwUtqk5BNs",
        "outputId": "6e541e82-f927-46b1-ec03-85f11bf76516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 4., 8.],\n",
              "        [9., 9., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inspace operation\n",
        "#in general what happens, when we perform any operation the result is saved in another memory thus taking more space which is not actually a good practice\n",
        "#therefore we can perform inspace operations\n",
        "\n",
        "a=torch.tensor([2,3],dtype=torch.float32)\n",
        "b=torch.tensor([3,4],dtype=torch.float32)\n",
        "#add_()\n",
        "a.add_(b)\n",
        "print(a)\n",
        "\n",
        "#sub_()\n",
        "a.sub_(b)\n",
        "print(a)\n",
        "\n",
        "#mul_()\n",
        "a.mul_(b)\n",
        "print(a)\n",
        "\n",
        "#div_()\n",
        "a.div_(b)\n",
        "print(a)\n",
        "\n",
        "#performing inplace operation basically requires underscore at the last. eg. add_, sub_ ...\n",
        "\n",
        "print(a.relu_()) # using this way to perform operation is permanently changing a tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e_iNKZySxek",
        "outputId": "8acfd170-af7a-4328-dfe2-ed944841d35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7.])\n",
            "tensor([2., 3.])\n",
            "tensor([ 6., 12.])\n",
            "tensor([2., 3.])\n",
            "tensor([2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.rand(2,3)\n",
        "b=a # in basic manner it is assignment operator so what should happen is that the value of a should be assigned to b , but for a change it doesn't work this way here.\n",
        "# instead it is like, that now you can access a from b also. so whatever changes will be there in b\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "VUyHAclEYZmu",
        "outputId": "2d197ca6-130d-4ee5-b751-4100ffc65e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7a9fd177ed07>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m \u001b[0;31m# in basic manner it is assignment operator so what should happen is that the value of a should be assigned to b , but for a change it doesn't work this way here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# instead it is like, that now you can access a from b also. so whatever changes will be there in b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2flpd7n1edYR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}